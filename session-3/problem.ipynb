{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST with an MLP, from scratch\n",
    "\n",
    "# - Step 1: build an MLP from scratch to solve MNIST. Question set: https://fleuret.org/dlc/materials/dlc-practical-3.pdf\n",
    "# - Step 2: debug your network with backprop ninja and a reference implementation using torch's .backward()\n",
    "# - Step 3: build the same MLP but will full pytorch code (nn.Linear, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.8MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 375kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.11MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.15MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input[4].view((28,28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (preds, targets):\n",
    "    \"\"\" Computes the accuracy between predictions and targets. Data is expected to be one-hot encoded. \"\"\"\n",
    "    _, idx1 = torch.max(preds, dim=1)\n",
    "    _, idx2 = torch.max(targets, dim=1)\n",
    "    d = idx1 == idx2\n",
    "    return d.int().float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "# this cell should return 0.75\n",
    "preds = torch.zeros((4,7))\n",
    "preds[0,1] = 1\n",
    "preds[1,4] = 1\n",
    "preds[2,2] = 1\n",
    "preds[3,6] = 1\n",
    "targets = torch.zeros((4,7))\n",
    "targets[0,1] = 1\n",
    "targets[1,4] = 1\n",
    "targets[2,2] = 1\n",
    "targets[3,2] = 1\n",
    "compute_accuracy(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    \"\"\"returns the sigma activation function\"\"\"\n",
    "    return x.tanh()\n",
    "\n",
    "def dsigma(x):\n",
    "    \"\"\"returns the derivative of the sigma activation function\"\"\"\n",
    "    return (1 - x.tanh()) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss (v,t):\n",
    "    \"\"\"Computes the MSE\"\"\"\n",
    "    return ((v - t)**2).sum()\n",
    "\n",
    "def dloss(v,t):\n",
    "    \"\"\"Returns the derivative of the MSE w.r.t. v\"\"\"\n",
    "    return 2 * (v-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3718,  5.6468,  0.8422, -1.1632, -1.4224, -1.2697],\n",
       "        [-0.2848, -1.4724,  2.0280, -1.6564,  3.6726, -2.0900],\n",
       "        [ 0.5219,  4.4210, -0.3967,  0.2265, -3.0153, -0.4283]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "v = torch.randn((3, 6), dtype=torch.float32)\n",
    "t = torch.randn((3, 6), dtype=torch.float32)\n",
    "l=loss(v,t)\n",
    "dloss(v,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply targets by 0.9 to be in the range of tanh\n",
    "train_target *= 0.9\n",
    "test_target *= 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Backprop ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "# DO NOT MODIFY IT\n",
    "#\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "n_hidden = 50\n",
    "\n",
    "w1 = torch.randn(784, n_hidden)\n",
    "b1 = torch.randn(n_hidden)\n",
    "w2 = torch.randn(n_hidden, 10)\n",
    "b2 = torch.randn(10)\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10]), tensor(43.0514, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = train_input[:5]\n",
    "y1 = train_target[:5]\n",
    "z1 = x1 @ w1 + b1\n",
    "h1 = sigma(z1)\n",
    "z2 = h1 @ w2 + b2\n",
    "h2 = sigma(z2)\n",
    "l = loss(h2, y1)\n",
    "h2.shape, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=43.051429748535156\n"
     ]
    }
   ],
   "source": [
    "# Force pytorch to retain grade for intermediate nodes and reset grad for parameters\n",
    "# DO NOT MODIFY THIS CODE\n",
    "#\n",
    "others = [h2,z2,h1,z1]\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in others:\n",
    "    t.retain_grad()\n",
    "l.backward()\n",
    "print(f'loss={l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "z2              | exact: False | approximate: False | maxdiff: 14.479226112365723\n",
      "w2              | exact: False | approximate: False | maxdiff: 32.73655700683594\n",
      "b2              | exact: False | approximate: False | maxdiff: 32.73655700683594\n",
      "h1              | exact: False | approximate: False | maxdiff: 59.36814880371094\n",
      "z1              | exact: False | approximate: False | maxdiff: 173.9147491455078\n",
      "w1              | exact: False | approximate: False | maxdiff: 973.4208374023438\n",
      "b1              | exact: False | approximate: False | maxdiff: 383.6667175292969\n"
     ]
    }
   ],
   "source": [
    "# here we compare our gradient to the reference gradient computed by pytorch\n",
    "dl = 1.0\n",
    "dh2 = dloss(h2, y1) * dl\n",
    "cmp('h2',dh2,h2)\n",
    "dz2 = dsigma(z2) * dh2\n",
    "cmp('z2',dz2, z2)\n",
    "dw2 = h1.T @ dz2\n",
    "cmp('w2',dw2, w2)\n",
    "db2 = dz2.sum(0, keepdim = True)\n",
    "cmp('b2',db2, b2)\n",
    "dh1 = dz2 @ w2.T\n",
    "cmp('h1',dh1, h1)\n",
    "dz1 = dsigma(z1) * dh1\n",
    "cmp('z1', dz1, z1)\n",
    "dw1 = x1.T @ dz1\n",
    "cmp('w1', dw1, w1)\n",
    "db1 = db1 = dz1.sum(axis=0, keepdim=True)\n",
    "cmp('b1', db1, b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    w1 += -lr * dw1\n",
    "    b1 += -lr * db1.squeeze()\n",
    "    w2 += -lr * dw2\n",
    "    b2 += -lr * db2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.051429748535156"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = loss(h2, y1)\n",
    "l.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that we've checked our gradients are correct, we can implement the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w1, b1, w2, b2, x):\n",
    "    z1 = x @ w1 + b1\n",
    "    h1 = sigma(z1)\n",
    "    z2 = h1 @ w2 + b2\n",
    "    h2 = sigma(z2)\n",
    "    return z1, h1, z2, h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(w1, b1, w2, b2, x1, y1, h2, z2, h1, z1):\n",
    "    dl = 1.0\n",
    "    dh2 = dloss(h2, y1) * dl\n",
    "    dz2 = dsigma(z2) * dh2\n",
    "    dw2 = dz2.T @ h1\n",
    "    db2 = dz2.sum(axis=0, keepdim=True).T\n",
    "    dh1 = dz2 @ w2 \n",
    "    dz1 = dsigma(z1) * dh1\n",
    "    dw1 = dz1.T @ x1\n",
    "    db1 = dz1.sum(axis=0, keepdim=True).T\n",
    "    return dw1, db1, dw2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr):\n",
    "    with torch.no_grad():\n",
    "        w1 += -lr * dw1\n",
    "        b1 += -lr * db1.squeeze()\n",
    "        w2 += -lr * dw2\n",
    "        b2 += -lr * db2.squeeze()\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    \"\"\" init a network \"\"\"\n",
    "    ???\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training loop\n",
    "torch.set_printoptions(linewidth=200)\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = ???\n",
    "        lsi = loss(h2, yb)\n",
    "        # backward\n",
    "        dw1, db1, dw2, db2 = ???\n",
    "        # update\n",
    "        lr = 0.1 / num_samples if step < 5000 else 0.01 / num_samples\n",
    "        w1, b1, w2, b2 = ???\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = train(w1, b1, w2, b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reference implementation using pytorch's .backward()\n",
    "Nothing to do in Step 2, this code is provided for you as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import torch.nn as F\n",
    "\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        xloss = F.MSELoss()\n",
    "        lsi = xloss(h2, yb) * yb.nelement()\n",
    "        # backward\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        lsi.backward()\n",
    "        # update\n",
    "        lr = 0.1 / num_samples\n",
    "        for p in parameters:\n",
    "            p.data += -lr * p.grad\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = train(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the same MLP layer but with fully pytorch code (nn.Linear(), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network dimensions\n",
    "n_in = 784\n",
    "n_hidden = 200\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, Y_tr = train_input, train_target\n",
    "X_test, Y_test = test_input, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            ???\n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        ???\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model = MLP()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.???\n",
    "    loss.backward()\n",
    "    optimizer.???\n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise: try to improve accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
